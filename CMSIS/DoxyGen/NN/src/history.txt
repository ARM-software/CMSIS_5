/**
\page ChangeLog_pg  Revision History of CMSIS-NN

<table class="cmtable" summary="Revision History">
  <tr>
    <th>Version</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>V3.0.0</td>
    <td>
    <ul>
      <li>Updated arm_fully_connected_s8 to use zero weight offset<br> 
      as per the TFLM int8 quantization spec. The API is the same but,<br>
      the weight offset parameter is expected to be zero<br> </li>
      <li> Added unit test for Softmax </li>
      <li> Added MVE optimiztion for SVDF operator </li>
      <li> Removed Examples folder </li>
      </ul>
    </td>
  </tr>
    <tr>
    <td>V2.0.0</td>
    <td>
      Added the following function for int8 SVDF operator.<br>
      <ul>
        <li>arm_svdf_s8</li>
      </ul>
      <ul>
        <li>arm_depthwise_conv_wrapper_s8</li>
        <li>arm_convolve_wrapper_s8</li>
        <li>arm_nn_doubling_high_mult_no_sat</li>
      </ul>
      Deleted functions
      <ul>
        <li>arm_max_pool_s8_opt</li>
      </ul>

    </td>
  </tr>
  <tr>
    <td>V1.3.0</td>
    <td>
      Added following functions for int8 operators with symmetric quantization.<br>
      <ul>
        <li>arm_convolve_s8</li>
        <li>arm_convolve_1x1_s8_fast</li>
        <li>arm_depthwise_conv_3x3_s8</li>
        <li>arm_depthwise_conv_s8</li>
        <li>arm_depthwise_conv_s8_opt</li>
        <li>arm_fully_connected_s8</li>
        <li>arm_softmax_q7</li>
        <li>arm_softmax_s8</li>
        <li>arm_softmax_u8</li>
        <li>arm_elementwise_mul_s8</li>
        <li>arm_elementwise_add_s8</li>
        <li>arm_avgpool_s8</li>
        <li>arm_maxpool_s8</li>
        <li>arm_maxpool_s8_opt</li>
        <li>arm_relu6_s8</li>
        <li>arm_reshape_s8</li>
        <li>arm_fully_connected_s8</li>
        <li>arm_concatenation_s8_w</li>
        <li>arm_concatenation_s8_x</li>
        <li>arm_concatenation_s8_y</li>
        <li>arm_concatenation_s8_z</li>
      </ul>
      Added following support functions.<br>
      <ul>
        <li>arm_nn_mat_mul_kernel_s8_s16</li>
        <li>arm_nn_mat_mul_kernel_s8_s16_reordered</li>
        <li>arm_nn_depthwise_conv_s8_core</li>
        <li>arm_nn_mat_mul_core_4x_s8</li>
        <li>arm_nn_mat_mul_core_1x_s8</li>
        <li>arm_convolve_1_x_n_s8</li>
        <li>arm_nn_vec_mat_mult_t_s8</li>
        <li>arm_nn_mat_mult_nt_t_s8</li>
        <li>arm_nn_depthwise_conv_nt_t_s8</li>
        <li>arm_nn_depthwise_conv_nt_t_padded_s8</li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>V1.2.0</td>
    <td>
      Added depthwise convolution function with asymmetric quantization.<br>
      <ul>
        <li>arm_depthwise_conv_u8_basic_ver1</li>
      </ul>
      Added support functions for requantization.<br>
      <ul>
        <li>arm_nn_sat_doubling_high_mult</li>
        <li>arm_nn_divide_by_power_of_two</li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>V1.1.0</td>
    <td>
      Added new math functions:<br>
      <ul>
        <li>arm_convolve_HWC_q7_basic_nonsquare</li>
        <li>arm_convolve_HWC_q15_fast_nonsquare</li>
        <li>arm_nn_mult_q7</li>
        <li>arm_nn_mult_q15</li>
      </ul>
      Fixed minor issues.
    </td>
  </tr>
  <tr>
    <td>V1.0.0</td>
    <td>
      Initial version
    </td>
  </tr>
</table>

*/
